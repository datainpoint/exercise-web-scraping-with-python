{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Data Analysis with Python\n",
    "\n",
    "> Web Scraping with Python\n",
    "\n",
    "Kuo, Yao-Jen <yaojenkuo@datainpoint.com> from [DATAINPOINT](https://www.datainpoint.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Instructions\n",
    "\n",
    "- We've imported necessary modules/libraries at the beginning of each exercise.\n",
    "- We've put necessary files(if any) in the working directory of each exercise.\n",
    "- We've defined the names of functions/inputs/arguments for you.\n",
    "- Write down your solution between the comments `### BEGIN SOLUTION` and `### END SOLUTION`.\n",
    "- Running tests to see if your solutions are right: Kernel -> Restart & Run All -> Restart and Run All Cells.\n",
    "- You can run tests after each question or after finishing all questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Define a function named `extract_team_names` that is able to extract the team names of NBA given a JSON file.\n",
    "\n",
    "- Expected inputs: a JSON file.\n",
    "- Expected outputs: a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_team_names(json_file):\n",
    "    \"\"\"\n",
    "    >>> team_names = extract_team_names('teams.json')\n",
    "    >>> len(team_names)\n",
    "    30\n",
    "    >>> \"Boston Celtics\" in team_names\n",
    "    True\n",
    "    >>> \"Brooklyn Nets\" in team_names\n",
    "    True\n",
    "    >>> \"Los Angeles Lakers\" in team_names\n",
    "    True\n",
    "    >>> \"Phoenix Suns\" in team_names\n",
    "    True\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(json_file) as jf:\n",
    "        teams_dict = json.load(jf)\n",
    "    nba_teams = teams_dict['league']['standard']\n",
    "    team_names = [e['fullName'] for e in nba_teams if e['isNBAFranchise']]\n",
    "    return team_names\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Define a function named `extract_store_addresses` that is able to extract the store addresses of 7-11 conveniece stores in Xinyi District, Taipei given a XML file.\n",
    "\n",
    "- Expected inputs: a XML file.\n",
    "- Expected outputs: a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_store_addresses(xml_file):\n",
    "    \"\"\"\n",
    "    >>> store_addresses = extract_store_addresses('stores.xml')\n",
    "    >>> len(store_addresses)\n",
    "    74\n",
    "    >>> '台北市信義區信義路五段7號35樓' in store_addresses\n",
    "    True\n",
    "    >>> '台北市信義區吳興街156巷2弄2號4號1樓' in store_addresses\n",
    "    True\n",
    "    >>> '台北市信義區忠孝東路五段68號24樓' in store_addresses\n",
    "    True\n",
    "    >>> '台北市信義區虎林街85號' in store_addresses\n",
    "    True\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    root = ET.parse(xml_file)\n",
    "    address_xpath = './/Address'\n",
    "    store_addresses = [e.text for e in root.findall(address_xpath)]\n",
    "    return store_addresses\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Define a function named `extract_movie_titles` that is able to extract the titles of top rated movies from IMDb.com given a HTML file.\n",
    "\n",
    "- Expected inputs: a HTML file.\n",
    "- Expected outputs: a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_titles(html_file):\n",
    "    \"\"\"\n",
    "    >>> movie_titles = extract_movie_titles('movies.html')\n",
    "    >>> len(movie_titles)\n",
    "    250\n",
    "    >>> 'The Shawshank Redemption' in movie_titles\n",
    "    True\n",
    "    >>> 'The Godfather' in movie_titles\n",
    "    True\n",
    "    >>> 'The Dark Knight' in movie_titles\n",
    "    True\n",
    "    >>> 'Forrest Gump' in movie_titles\n",
    "    True\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(html_file) as hf:\n",
    "        soup = BeautifulSoup(hf)\n",
    "    movie_titles = [e.text for e in soup.select('.titleColumn a')]\n",
    "    return movie_titles\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Define a function named `extract_movie_ratings` that is able to extract the ratings of top rated movies from IMDb.com given a HTML file.\n",
    "\n",
    "- Expected inputs: a HTML file.\n",
    "- Expected outputs: a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_ratings(html_file):\n",
    "    \"\"\"\n",
    "    >>> movie_ratings = extract_movie_ratings('movies.html')\n",
    "    >>> len(movie_ratings)\n",
    "    250\n",
    "    >>> max(movie_ratings)\n",
    "    9.2\n",
    "    >>> min(movie_ratings)\n",
    "    8.0\n",
    "    >>> sum(movie_ratings) / len(movie_ratings)\n",
    "    8.253999999999975\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(html_file) as hf:\n",
    "        soup = BeautifulSoup(hf)\n",
    "    movie_ratings = [float(e.text) for e in soup.select('strong')]\n",
    "    return movie_ratings\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Run tests!\n",
    "\n",
    "Kernel -> Restart & Run All -> Restart and Run All Cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_00_extract_team_names (__main__.TestWebScraping) ... ok\n",
      "test_01_extract_store_addresses (__main__.TestWebScraping) ... ok\n",
      "test_02_extract_movie_titles (__main__.TestWebScraping) ... ok\n",
      "test_03_extract_movie_ratings (__main__.TestWebScraping) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 1.219s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestWebScraping(unittest.TestCase):\n",
    "    def test_00_extract_team_names(self):\n",
    "        team_names = extract_team_names('teams.json')\n",
    "        self.assertEqual(len(team_names), 30)\n",
    "        self.assertTrue(\"Boston Celtics\" in team_names)\n",
    "        self.assertTrue(\"Brooklyn Nets\" in team_names)\n",
    "        self.assertTrue(\"Los Angeles Lakers\" in team_names)\n",
    "        self.assertTrue(\"Phoenix Suns\" in team_names)\n",
    "    def test_01_extract_store_addresses(self):\n",
    "        store_addresses = extract_store_addresses('stores.xml')\n",
    "        self.assertEqual(len(store_addresses), 74)\n",
    "        self.assertTrue('台北市信義區信義路五段7號35樓' in store_addresses)\n",
    "        self.assertTrue('台北市信義區吳興街156巷2弄2號4號1樓' in store_addresses)\n",
    "        self.assertTrue('台北市信義區忠孝東路五段68號24樓' in store_addresses)\n",
    "        self.assertTrue('台北市信義區虎林街85號' in store_addresses)\n",
    "    def test_02_extract_movie_titles(self):\n",
    "        movie_titles = extract_movie_titles('movies.html')\n",
    "        self.assertEqual(len(movie_titles), 250)\n",
    "        self.assertTrue('The Shawshank Redemption' in movie_titles)\n",
    "        self.assertTrue('The Godfather' in movie_titles)\n",
    "        self.assertTrue('The Dark Knight' in movie_titles)\n",
    "        self.assertTrue('Forrest Gump' in movie_titles)\n",
    "    def test_03_extract_movie_ratings(self):\n",
    "        movie_ratings = extract_movie_ratings('movies.html')\n",
    "        self.assertEqual(len(movie_ratings), 250)\n",
    "        self.assertAlmostEqual(max(movie_ratings), 9.2)\n",
    "        self.assertAlmostEqual(min(movie_ratings), 8.0)\n",
    "        self.assertAlmostEqual(sum(movie_ratings) / len(movie_ratings), 8.253999999999975)\n",
    "        \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestWebScraping)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "test_results = runner.run(suite)\n",
    "number_of_failures = len(test_results.failures)\n",
    "number_of_errors = len(test_results.errors)\n",
    "number_of_test_runs = test_results.testsRun\n",
    "number_of_successes = number_of_test_runs - (number_of_failures + number_of_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've got 4 successes among 4 questions.\n"
     ]
    }
   ],
   "source": [
    "print(\"You've got {} successes among {} questions.\".format(number_of_successes, number_of_test_runs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Data Analysis",
   "language": "python",
   "name": "pyda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
